{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 第11回講義 演習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 課題2. Attentionを用いたキャプション生成モデルの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. データセットの読み込みと概観"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Microsoft Common Objects in Context (MS COCO)という, 画像・キャプション・セグメンテーションなどがペアになったデータセットを使用します.\n",
    "\n",
    "画像とキャプションのペアは全部で約8万3000件ありますが, 今回は計算時間やメモリ使用量などの観点から10000ペアに絞って使用します.\n",
    "\n",
    "前処理済みのデータがaws上にあるので, それをダウンロードして使います.\n",
    "\n",
    "- MS COCO: http://mscoco.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %%bash # 一度だけ実行してください\n",
    "# wget -q https://s3.amazonaws.com/ilect-public/ail/mscoco_captions_10000.txt # キャプションデータ\n",
    "# wget -q https://s3.amazonaws.com/ilect-public/ail/mscoco_images_10000.npy # 画像データ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 1.1. 読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_vocab(file_path, target):\n",
    "    vocab = set()\n",
    "    for line in open(file_path, encoding='utf-8'):\n",
    "        words = line.strip().split()\n",
    "        vocab.update(words)\n",
    "\n",
    "    if target:\n",
    "        w2i = {w: np.int32(i+2) for i, w in enumerate(vocab)}\n",
    "        w2i['<s>'], w2i['</s>'] = np.int32(0), np.int32(1) # 文の先頭・終端記号\n",
    "    else:\n",
    "        w2i = {w: np.int32(i) for i, w in enumerate(vocab)}\n",
    "\n",
    "    return w2i\n",
    "\n",
    "def encode(sentence, w2i):\n",
    "    encoded_sentence = []\n",
    "    for w in sentence:\n",
    "        encoded_sentence.append(w2i[w])\n",
    "    return encoded_sentence\n",
    "\n",
    "def load_data(file_path, vocab=None, w2i=None, target=True):\n",
    "    if vocab is None and w2i is None:\n",
    "        w2i = build_vocab(file_path, target)\n",
    "    \n",
    "    data = []\n",
    "    for line in open(file_path, encoding='utf-8'):\n",
    "        s = line.strip().split()\n",
    "        if target:\n",
    "            s = ['<s>'] + s + ['</s>']\n",
    "        enc = encode(s, w2i)\n",
    "        data.append(enc)\n",
    "    i2w = {i: w for w, i in w2i.items()}\n",
    "    return data, w2i, i2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_y, w2i, i2w = load_data('./mscoco_captions_10000.txt', target=True)\n",
    "train_X = np.load('./mscoco_images_10000.npy')\n",
    "\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "今回はencoderの入力は画像でサイズは固定なので, decoderの入力$y$でソートします."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_y_lens = [len(com) for com in train_y]\n",
    "valid_y_lens = [len(com) for com in valid_y]\n",
    "sorted_train_indexes = sorted(range(len(train_y_lens)), key=lambda x: -train_y_lens[x])\n",
    "sorted_valid_indexes = sorted(range(len(valid_y_lens)), key=lambda x: -valid_y_lens[x])\n",
    "\n",
    "train_X = [train_X[ind] for ind in sorted_train_indexes]\n",
    "train_y = [train_y[ind] for ind in sorted_train_indexes]\n",
    "valid_X = [valid_X[ind] for ind in sorted_valid_indexes]\n",
    "valid_y = [valid_y[ind] for ind in sorted_valid_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 1.2. データセットの中身"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num = 0\n",
    "\n",
    "print(' '.join([i2w[com] for com in train_y[num][1:-1]]))\n",
    "plt.imshow(train_X[num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. 各層クラスの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "次のモデルを実装します."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"attention-2.png\" size=\"1000mm\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "まず224x224x3の画像をEncoder (CNN) で特徴量マップ$u$に落とし込み, それを元にDecoder (LSTM + Attention) でキャプションを生成していきます."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 2.1. Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "まずCNNに必要なクラスを実装していきます. これらはchap8で用いたものと同じです.\n",
    "\n",
    "今回は, CNNは学習済みのモデルを使います. これは`Keras.applications`から読み込むことができます. Convクラスでは学習済みの重みを`tf.Variable`の初期値とするために, コンストラクタの引数に初期値を取れるよう書いています.\n",
    "\n",
    "また, `tf.Variable`の`trainable`オプションを`False`にすることで, パラメータの更新をしないようにしています."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Conv:\n",
    "    def __init__(self, filter_shape, W, b, function=lambda x: x, strides=[1,1,1,1], padding='VALID'):\n",
    "        # Xavier\n",
    "        fan_in = np.prod(filter_shape[:3])\n",
    "        fan_out = np.prod(filter_shape[:2]) * filter_shape[3]\n",
    "        self.W = tf.Variable(W, trainable=False, name='W')\n",
    "        self.b = tf.Variable(b, trainable=False, name='b')\n",
    "        self.function = function\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "\n",
    "    def f_prop(self, x):\n",
    "        conv_out = tf.nn.conv2d(x, self.W, strides=self.strides, padding=self.padding)\n",
    "        return self.function(tf.nn.bias_add(conv_out, self.b)) # broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID'):\n",
    "        self.ksize = ksize\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "    \n",
    "    def f_prop(self, x):\n",
    "        return tf.nn.max_pool(x, ksize=self.ksize, strides=self.strides, padding=self.padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 入力xが行列([batch_size, hid_dim])の全結合層\n",
    "class Dense2d:\n",
    "    def __init__(self, in_dim, out_dim, function=lambda x: x):\n",
    "        # Xavier\n",
    "        self.W = tf.Variable(rng.uniform(\n",
    "                        low=-np.sqrt(6/(in_dim + out_dim)),\n",
    "                        high=np.sqrt(6/(in_dim + out_dim)),\n",
    "                        size=(in_dim, out_dim)\n",
    "                    ).astype('float32'), name='W')\n",
    "        self.b = tf.Variable(np.zeros([out_dim]).astype('float32'))\n",
    "        self.function = function\n",
    "\n",
    "    def f_prop(self, x):\n",
    "        return self.function(tf.matmul(x, self.W) + self.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 2.2. Decoder\n",
    "\n",
    "次にDecoderのためのクラスを設定していきます. Embedding, Dense層はChap10で用いたものと同じです. LSTM層はmaskがない所以外は同じです. (LSTMはDecoderでのみ使うので, maskは必要ないです)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    def __init__(self, vocab_size, emb_dim, scale=0.08):\n",
    "        self.V = tf.Variable(rng.randn(vocab_size, emb_dim).astype('float32') * scale, name='V')\n",
    "\n",
    "    def f_prop(self, x):\n",
    "        return tf.nn.embedding_lookup(self.V, x)\n",
    "    \n",
    "    def f_prop_test(self, x_t):\n",
    "        return tf.nn.embedding_lookup(self.V, x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    def __init__(self, in_dim, hid_dim, h_0=None, c_0=None):\n",
    "        self.in_dim = in_dim\n",
    "        self.hid_dim = hid_dim\n",
    "\n",
    "        # input gate\n",
    "        self.W_xi = tf.Variable(tf.random_uniform([in_dim, hid_dim], minval=-0.08, maxval=0.08, dtype=tf.float32), name='W_xi')\n",
    "        self.W_hi = tf.Variable(tf.random_uniform([hid_dim, hid_dim], minval=-0.08, maxval=0.08, dtype=tf.float32), name='W_hi')\n",
    "        self.b_i  = tf.Variable(tf.random_uniform([hid_dim], minval=-0.08, maxval=0.08, dtype=tf.float32), name='b_i')\n",
    "        \n",
    "        # forget gate\n",
    "        self.W_xf = tf.Variable(tf.random_uniform([in_dim, hid_dim], minval=-0.08, maxval=0.08, dtype=tf.float32), name='W_xf')\n",
    "        self.W_hf = tf.Variable(tf.random_uniform([hid_dim, hid_dim], minval=-0.08, maxval=0.08, dtype=tf.float32), name='W_hf')\n",
    "        self.b_f  = tf.Variable(tf.random_uniform([hid_dim], minval=-0.08, maxval=0.08, dtype=tf.float32), name='b_f')\n",
    "        \n",
    "        # cell state\n",
    "        self.W_xc = tf.Variable(tf.random_uniform([in_dim, hid_dim], minval=-0.08, maxval=0.08, dtype=tf.float32), name='W_xc')\n",
    "        self.W_hc = tf.Variable(tf.random_uniform([hid_dim, hid_dim], minval=-0.08, maxval=0.08, dtype=tf.float32), name='W_hc')\n",
    "        self.b_c  = tf.Variable(tf.random_uniform([hid_dim], minval=-0.08, maxval=0.08, dtype=tf.float32), name='b_c')\n",
    "        \n",
    "        # output gate\n",
    "        self.W_xo = tf.Variable(tf.random_uniform([in_dim, hid_dim], minval=-0.08, maxval=0.08, dtype=tf.float32), name='W_xo')\n",
    "        self.W_ho = tf.Variable(tf.random_uniform([hid_dim, hid_dim], minval=-0.08, maxval=0.08, dtype=tf.float32), name='W_ho')\n",
    "        self.b_o  = tf.Variable(tf.random_uniform([hid_dim], minval=-0.08, maxval=0.08, dtype=tf.float32), name='b_o')\n",
    "\n",
    "        # initial state\n",
    "        self.h_0 = h_0\n",
    "        self.c_0 = c_0\n",
    "\n",
    "    def f_prop(self, x):\n",
    "        def fn(tm1, x_t):\n",
    "            h_tm1 = tm1[0]\n",
    "            c_tm1 = tm1[1]\n",
    "            # input gate\n",
    "            i_t = tf.nn.sigmoid(tf.matmul(x_t, self.W_xi) + tf.matmul(h_tm1, self.W_hi) + self.b_i)\n",
    "\n",
    "            # forget gate\n",
    "            f_t = tf.nn.sigmoid(tf.matmul(x_t, self.W_xf) + tf.matmul(h_tm1, self.W_hf) + self.b_f)\n",
    "\n",
    "            # cell state\n",
    "            c_t = f_t * c_tm1 + i_t * tf.nn.tanh(tf.matmul(x_t, self.W_xc) + tf.matmul(h_tm1, self.W_hc) + self.b_c)\n",
    "\n",
    "            # output gate\n",
    "            o_t = tf.nn.sigmoid(tf.matmul(x_t, self.W_xo) + tf.matmul(h_tm1, self.W_ho) + self.b_o)\n",
    "\n",
    "            # hidden state\n",
    "            h_t = o_t * tf.nn.tanh(c_t)\n",
    "\n",
    "            return [h_t, c_t]\n",
    "\n",
    "        _x = tf.transpose(x, perm=[1, 0, 2])\n",
    "\n",
    "        if self.h_0 == None:\n",
    "            self.h_0 = tf.matmul(x[:, 0, :], tf.zeros([self.in_dim, self.hid_dim]))\n",
    "        if self.c_0 == None:\n",
    "            self.c_0 = tf.matmul(x[:, 0, :], tf.zeros([self.in_dim, self.hid_dim]))\n",
    "\n",
    "        h, c = tf.scan(fn=fn, elems=_x, initializer=[self.h_0, self.c_0])\n",
    "        return tf.transpose(h, perm=[1, 0, 2]), tf.transpose(c, perm=[1, 0, 2])\n",
    "\n",
    "    def f_prop_test(self, x_t):\n",
    "        # input gate\n",
    "        i_t = tf.nn.sigmoid(tf.matmul(x_t, self.W_xi) + tf.matmul(self.h_0, self.W_hi) + self.b_i)\n",
    "\n",
    "        # forget gate\n",
    "        f_t = tf.nn.sigmoid(tf.matmul(x_t, self.W_xf) + tf.matmul(self.h_0, self.W_hf) + self.b_f)\n",
    "\n",
    "        # output gate\n",
    "        o_t = tf.nn.sigmoid(tf.matmul(x_t, self.W_xo) + tf.matmul(self.h_0, self.W_ho) + self.b_o)\n",
    "\n",
    "        # cell state\n",
    "        c_t = f_t * self.c_0 + i_t * tf.nn.tanh(tf.matmul(x_t, self.W_xc) + tf.matmul(self.h_0, self.W_hc) + self.b_c)\n",
    "\n",
    "        # hidden state\n",
    "        h_t = o_t * tf.nn.tanh(c_t)\n",
    "\n",
    "        return [h_t, c_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 入力xが3階テンソル([batch_size, sentence_length, hid_dim])の全結合層\n",
    "class Dense:\n",
    "    def __init__(self, in_dim, out_dim, function=lambda x: x):\n",
    "        # Xavier\n",
    "        self.W = tf.Variable(rng.uniform(\n",
    "                        low=-np.sqrt(6/(in_dim + out_dim)),\n",
    "                        high=np.sqrt(6/(in_dim + out_dim)),\n",
    "                        size=(in_dim, out_dim)\n",
    "                    ).astype('float32'), name='W')\n",
    "        self.b = tf.Variable(tf.zeros([out_dim], dtype=tf.float32), name='b')\n",
    "        self.function = function\n",
    "\n",
    "    def f_prop(self, x):\n",
    "        return self.function(tf.einsum('ijk,kl->ijl', x, self.W) + self.b)\n",
    "\n",
    "    def f_prop_test(self, x_t):\n",
    "        return self.function(tf.matmul(x_t, self.W) + self.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Attention層\n",
    "\n",
    "簡単のため, attention層は翻訳で用いたものとほぼ同じものを使用します. 違いとして, 翻訳ではmaskを設定しましたが, 今回はEncoderの出力は固定長なのでmaskは必要ないです.\n",
    "\n",
    "「入力のどこに注目するか」は, 翻訳ではEncoderの各ステップの隠れ層でしたが, キャプション生成ではCNNで獲得したサイズ14x14の特徴量マップに対しておこないます. 14x14のままでは扱いにくいので, 長さ196 (=14x14) のベクトルにflattenしてから処理します.\n",
    "\n",
    "今回の演習では細かい部分は省略していますが, 実際のアテンション付きキャプション生成の論文ではさらに,\n",
    "- attention層で計算した文脈ベクトルをLSTMにfeedしている\n",
    "- 出力層での計算にも単語の埋め込みベクトルを用いている\n",
    "- Encoderに19層のVGGをつかっている.\n",
    "\n",
    "などとしています. 詳細は論文を参照してください.\n",
    "- \"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\", Kelvin Xu et al., ICML 2015 https://arxiv.org/abs/1502.03044"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Attention:\n",
    "    def __init__(self, cnn_dim, rnn_dim, out_dim, u):\n",
    "        self.W_cc = tf.Variable(rng.uniform(low=-0.08, high=0.08, size=[cnn_dim, out_dim]).astype('float32'), name='W_cc')\n",
    "        self.W_ch = tf.Variable(rng.uniform(low=-0.08, high=0.08, size=[rnn_dim, out_dim]).astype('float32'), name='W_ch')\n",
    "        self.W_a = tf.Variable(rng.uniform(low=-0.08, high=0.08, size=[cnn_dim, rnn_dim]).astype('float32'), name='W_a')\n",
    "        self.b = tf.Variable(np.zeros(out_dim).astype('float32'), name='b')\n",
    "        self.u = u\n",
    "\n",
    "    def f_prop(self, h_dec):\n",
    "        u = tf.einsum('ijk,kl->ijl', self.u, self.W_a)\n",
    "        score = tf.einsum('ijk,ilk->ijl', h_dec, u) # Attention score\n",
    "        self.a = tf.nn.softmax(score) # Attention weight\n",
    "        c = tf.einsum('ijk,ikl->ijl', self.a, self.u) # Context vector\n",
    "        return tf.nn.tanh(tf.einsum('ijk,kl->ijl', c, self.W_cc) + tf.einsum('ijk,kl->ijl', h_dec, self.W_ch) + self.b)\n",
    "\n",
    "    def f_prop_test(self, h_dec_t):\n",
    "        u = tf.einsum('ijk,kl->ijl', self.u, self.W_a)\n",
    "        score = tf.einsum('ij,ikj->ik', h_dec_t, u) # Attention score\n",
    "        self.a = tf.nn.softmax(score) # Attention weight\n",
    "        c = tf.einsum('ij,ijk->ik', self.a, self.u) # Context vector\n",
    "        return tf.nn.tanh(tf.matmul(c, self.W_cc) + tf.matmul(h_dec_t, self.W_ch) + self.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 4. 計算グラフの構築 & パラメータの更新設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 4.1. Pre-trained modelの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "CNNは16層のVGGネットワークを使います. また, Kerasに訓練済みのモデルがあるので, そちらをloadし重みを取得して, `tf.Variable`の初期値として使います.\n",
    "\n",
    "- \"Very Deep Convolutional Networks for Large-Scale Image Recognition\", Karen Simonyan et al., ICLR 2015 https://arxiv.org/abs/1409.1556\n",
    "- Keras Applications: https://keras.io/applications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = VGG16()\n",
    "\n",
    "weights = [com.get_weights() for com in model.layers[1:]] # 各層の重み(W, b)を取得."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 4.2. グラフの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "vocab_size = len(i2w)\n",
    "emb_dim = 64\n",
    "rnn_dim = 64\n",
    "att_dim = 64\n",
    "hid_dim = 64\n",
    "mlp_dim = 64\n",
    "cnn_dim = 512\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "d = tf.placeholder(tf.int32, [None, None], name='d')\n",
    "d_in = d[:, :-1]\n",
    "d_out = d[:, 1:]\n",
    "d_out_one_hot = tf.one_hot(d_out, depth=vocab_size, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# 16-layer VGG\n",
    "cnn_layers = [\n",
    "    Conv((3, 3, 3, 64), weights[0][0], weights[0][1], tf.nn.relu, padding='SAME'), # 224x224x3 -> 224x224x64\n",
    "    Conv((3, 3, 64, 64), weights[1][0], weights[1][1], tf.nn.relu, padding='SAME'), # 224x224x64 -> 224x224x64\n",
    "    Pooling((1, 2, 2, 1)), # 224x224x64 -> 112x112x64\n",
    "    Conv((3, 3, 64, 128), weights[3][0], weights[3][1], tf.nn.relu, padding='SAME'), # 112x112x64 -> 112x112x128\n",
    "    Conv((3, 3, 128, 128), weights[4][0], weights[4][1], tf.nn.relu, padding='SAME'), # 112x112x128 -> 112x112x128\n",
    "    Pooling((1, 2, 2, 1)), # 112x112x128 -> 56x56x128\n",
    "    Conv((3, 3, 128, 256), weights[6][0], weights[6][1], tf.nn.relu, padding='SAME'), # 56x56x128 -> 56x56x256\n",
    "    Conv((3, 3, 256, 256), weights[7][0], weights[7][1], tf.nn.relu, padding='SAME'), # 56x56x256 -> 56x56x256\n",
    "    Conv((3, 3, 256, 256), weights[8][0], weights[8][1], tf.nn.relu, padding='SAME'), # 56x56x256 -> 56x56x256\n",
    "    Pooling((1, 2, 2, 1)), # 56x56x256 -> 28x28x256\n",
    "    Conv((3, 3, 256, 512), weights[10][0], weights[10][1], tf.nn.relu, padding='SAME'), # 28x28x256 -> 28x28x512\n",
    "    Conv((3, 3, 512, 512), weights[11][0], weights[11][1], tf.nn.relu, padding='SAME'), # 28x28x512 -> 28x28x512\n",
    "    Conv((3, 3, 512, 512), weights[12][0], weights[12][1], tf.nn.relu, padding='SAME'), # 28x28x512 -> 28x28x512\n",
    "    Pooling((1, 2, 2, 1)), # 28x28x512 -> 14x14x512\n",
    "    Conv((3, 3, 512, 512), weights[14][0], weights[14][1], tf.nn.relu, padding='SAME'), # 14x14x512 -> 14x14x512\n",
    "    Conv((3, 3, 512, 512), weights[15][0], weights[15][1], tf.nn.relu, padding='SAME'), # 14x14x512 -> 14x14x512\n",
    "    Conv((3, 3, 512, 512), weights[16][0], weights[16][1], tf.nn.relu, padding='SAME'), # 14x14x512 -> 14x14x512\n",
    "]\n",
    "\n",
    "def f_props(layers, x):\n",
    "    for layer in layers:\n",
    "        x = layer.f_prop(x)\n",
    "    return x\n",
    "\n",
    "u_ = f_props(cnn_layers, x)\n",
    "u = tf.reshape(u_, [-1, 196, 512]) # 14x14x512 -> 196x512\n",
    "\n",
    "u_mean = tf.reduce_mean(u, axis=1)\n",
    "\n",
    "# LSTMのセルの初期値を獲得するネットワーク\n",
    "mlp_layers_c = [\n",
    "    Dense2d(512, rnn_dim, tf.nn.tanh),\n",
    "]\n",
    "\n",
    "# LSTMの隠れ層ベクトルの初期値を獲得するネットワーク\n",
    "mlp_layers_h = [\n",
    "    Dense2d(512, rnn_dim, tf.nn.tanh),\n",
    "]\n",
    "\n",
    "c_init = f_props(mlp_layers_c, u_mean) # LSTMのセルの初期値\n",
    "h_init = f_props(mlp_layers_h, u_mean) # LSTMの隠れ層ベクトルの初期値\n",
    "\n",
    "decoder_pre = [\n",
    "    Embedding(vocab_size, emb_dim),\n",
    "    LSTM(emb_dim, hid_dim, h_init, c_init)\n",
    "]\n",
    "\n",
    "decoder_post = [\n",
    "    Attention(cnn_dim, rnn_dim, hid_dim, u),\n",
    "    Dense(hid_dim, vocab_size, tf.nn.softmax)\n",
    "]\n",
    "\n",
    "h_dec, c_dec = f_props(decoder_pre, d_in)\n",
    "y = f_props(decoder_post, h_dec)\n",
    "\n",
    "cost = -tf.reduce_mean(tf.reduce_sum(d_out_one_hot * tf.log(tf.clip_by_value(y, 1e-10, 1.0)), axis=[1,2]))\n",
    "\n",
    "train = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 5. 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 32\n",
    "n_batches_train = len(train_X)//batch_size\n",
    "n_batches_valid = len(valid_X)//batch_size\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(n_epochs):\n",
    "    # Train\n",
    "    train_costs = []\n",
    "    for i in range(n_batches_train):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        train_X_mb = train_X[start:end]\n",
    "        train_y_mb = np.array(pad_sequences(train_y[start:end], padding='post', value=-1))\n",
    "        \n",
    "        _, train_cost = sess.run([train, cost], feed_dict={x: train_X_mb, d: train_y_mb})\n",
    "\n",
    "        train_costs.append(train_cost)\n",
    "\n",
    "    # Valid\n",
    "    valid_costs = []\n",
    "    for i in range(n_batches_valid):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        \n",
    "        valid_X_mb = np.array(valid_X[start:end])\n",
    "        valid_y_mb = np.array(pad_sequences(valid_y[start:end], padding='post', value=-1))\n",
    "        \n",
    "        valid_cost = sess.run(cost, feed_dict={x: valid_X_mb, d: valid_y_mb})\n",
    "        \n",
    "        valid_costs.append(valid_cost)\n",
    "\n",
    "    print('EPOCH: %i, Training cost: %.3f, Validation cost: %.3f' % (epoch+1, np.mean(train_costs), np.mean(valid_costs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 6. キャプションの生成と Attention weight の可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 6.1. グラフの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t_0 = tf.constant(0)\n",
    "h_0 = tf.placeholder(tf.float32, [None, None], name='h_0')\n",
    "c_0 = tf.placeholder(tf.float32, [None, None], name='c_0')\n",
    "y_0 = tf.placeholder(tf.int32, [None, None], name='y_0')\n",
    "a_0 = tf.zeros_like(decoder_post[0].u[:, :, :1], dtype=tf.float32, name='a_0')\n",
    "f_0 = tf.cast(tf.zeros_like(y_0[:, 0]), dtype=tf.bool) # バッチ内の各サンプルに対して</s>が出たかどうかのflag\n",
    "\n",
    "f_0_size = tf.reduce_sum(tf.ones_like(f_0, dtype=tf.int32))\n",
    "max_len = tf.placeholder(tf.int32, name='max_len') # iterationの繰り返し回数の限度\n",
    "\n",
    "def f_props_test(layers, x_t):\n",
    "    for layer in layers:\n",
    "        x_t = layer.f_prop_test(x_t)\n",
    "    return x_t\n",
    "\n",
    "def cond(t, h_t, c_t, y_t, a_t, f_t):\n",
    "    num_true = tf.reduce_sum(tf.cast(f_t, tf.int32)) # Trueの数\n",
    "    unfinished = tf.not_equal(num_true, f_0_size)\n",
    "    return tf.logical_and(t+1 < max_len, unfinished)\n",
    "\n",
    "def body(t, h_tm1, c_tm1, y, a, f_tm1):\n",
    "    y_tm1 = y[:, -1]\n",
    "\n",
    "    decoder_pre[1].h_0 = h_tm1\n",
    "    decoder_pre[1].c_0 = c_tm1\n",
    "    h_t, c_t = f_props_test(decoder_pre, y_tm1)\n",
    "    y_t = tf.cast(tf.argmax(f_props_test(decoder_post, h_t), axis=1), tf.int32)\n",
    "    a_t = decoder_post[0].a\n",
    "    \n",
    "    y = tf.concat([y, y_t[:, np.newaxis]], axis=1)\n",
    "    a = tf.concat([a, a_t[:, :, np.newaxis]], axis=2)\n",
    "    \n",
    "    f_t = tf.logical_or(f_tm1, tf.equal(y_t, 1))\n",
    "    \n",
    "    return [t+1, h_t, c_t, y, a, f_t]\n",
    "\n",
    "res = tf.while_loop(\n",
    "    cond,\n",
    "    body,\n",
    "    loop_vars=[t_0, h_0, c_0, y_0, a_0, f_0],\n",
    "    shape_invariants=[\n",
    "        t_0.get_shape(),\n",
    "        tf.TensorShape([None, None]),\n",
    "        tf.TensorShape([None, None]),\n",
    "        tf.TensorShape([None, None]),\n",
    "        tf.TensorShape([None, None, None]),\n",
    "        tf.TensorShape([None])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 6.2. 生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "valid_X_mb = np.array(valid_X[0:32])\n",
    "_y_0 = np.zeros([len(valid_X[0:32]), 1], dtype='int32')\n",
    "\n",
    "_h_0, _c_0, _u = sess.run([h_init, c_init, u], feed_dict={x: valid_X_mb})\n",
    "\n",
    "_, _, _, pred_y, att_weights, _ = sess.run(res, feed_dict={\n",
    "    decoder_post[0].u: _u,\n",
    "    y_0: _y_0,\n",
    "    h_0: _h_0,\n",
    "    c_0: _c_0,\n",
    "    max_len: 100\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 6.3. アテンションの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num = 0\n",
    "\n",
    "truex = valid_X[num]\n",
    "predy = pred_y[num].tolist()[1:pred_y[num].tolist().index(1)]\n",
    "truey = valid_y[num][1:-1]\n",
    "aa = att_weights[num][:, 1:len(predy)+1].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "画像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(truex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "生成されたキャプションと正解キャプション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('生成文されたキャプション:', ' '.join([i2w[com] for com in predy]))\n",
    "print('正解キャプション:', ' '.join([i2w[com] for com in truey]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "アテンションの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 10))\n",
    "\n",
    "for i, (word, a) in enumerate(zip(predy, aa)):\n",
    "    ax = fig.add_subplot(4, 5, i+1)\n",
    "    \n",
    "    # Plot image\n",
    "    ax.imshow(truex)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Plot attention\n",
    "    a = skimage.transform.pyramid_expand(a.reshape(14, 14), upscale=16, sigma=20)\n",
    "    ax.imshow(a, alpha=.65)\n",
    "    \n",
    "    # Plot word\n",
    "    ax.set_title(i2w[word])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
