{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第6回講義 演習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題1. Denoising Autoencoderの実装. また, MNISTを用いて次のことを確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- reconstruction errorが小さくなっている（学習が進んでいる）\n",
    "- 重みの可視化（特徴の可視化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. MNISTデータセットの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n",
    "mnist_X, mnist_y = mnist.train.images, mnist.train.labels\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(mnist_X, mnist_y, test_size=0.1, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Autoencoderの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Autoencoder:\n",
    "    def __init__(self, vis_dim, hid_dim, function=lambda x: x):\n",
    "        self.W = tf.Variable(rng.uniform(low=-0.08, high=0.08, size=(vis_dim, hid_dim)).astype('float32'), name='W')\n",
    "        self.a = tf.Variable(np.zeros(vis_dim).astype('float32'), name='a')\n",
    "        self.b = tf.Variable(np.zeros(hid_dim).astype('float32'), name='b')\n",
    "        self.function = function\n",
    "        self.params = [self.W, self.a, self.b]\n",
    "\n",
    "    def encode(self, x):\n",
    "        u = tf.matmul(x, self.W) + self.b\n",
    "        return self.function(u)\n",
    "\n",
    "    def decode(self, x):\n",
    "        u = tf.matmul(x, tf.transpose(self.W)) + self.a\n",
    "        return self.function(u)\n",
    "\n",
    "    def f_prop(self, x):\n",
    "        y = self.encode(x)\n",
    "        return self.decode(y)\n",
    "\n",
    "    def reconst_error(self, x, noise):\n",
    "        tilde_x = x * noise\n",
    "        reconst_x = self.f_prop(tilde_x)\n",
    "        error = -tf.reduce_mean(tf.reduce_sum(x * tf.log(reconst_x) + (1. - x) * tf.log(1. - reconst_x), axis=1))\n",
    "        return error, reconst_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 確率的勾配法 (Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd(cost, params, eps=np.float32(0.1)):\n",
    "    g_params = tf.gradients(cost, params)\n",
    "    updates = []\n",
    "    for param, g_param in zip(params, g_params):\n",
    "        if g_param != None:\n",
    "            updates.append(param.assign_add(-eps*g_param))\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. モデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.copy(train_X)\n",
    "\n",
    "model = Autoencoder(X.shape[1], 500, tf.nn.sigmoid)\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784], name='x')\n",
    "noise = tf.placeholder(tf.float32, [None, 784], name='noise')\n",
    "\n",
    "cost, reconst_x = model.reconst_error(x, noise)\n",
    "params = model.params\n",
    "updates = sgd(cost, params)\n",
    "train = tf.group(*updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Corruption level=0の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = X.shape[0]//batch_size\n",
    "\n",
    "corruption_level = np.float32(0.0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        X = shuffle(X, random_state=random_state)\n",
    "        err_all = []\n",
    "        for i in range(n_batches):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "\n",
    "            _noise = rng.binomial(size=X[start:end].shape, n=1, p=1-corruption_level)\n",
    "            _, err = sess.run([train, cost], feed_dict={x: X[start:end], noise: _noise})\n",
    "            err_all.append(err)\n",
    "        print('EPOCH:%d, ERROR:%lf' % (epoch+1, np.mean(err_all)))\n",
    "\n",
    "    weight_1 = sess.run(tf.transpose(model.W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Corruption level=0.3の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corruption_level = np.float32(0.3)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        X = shuffle(X, random_state=random_state)\n",
    "        err_all = []\n",
    "        for i in range(n_batches):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "\n",
    "            _noise = rng.binomial(size=X[start:end].shape, n=1, p=1-corruption_level)\n",
    "            _, err = sess.run([train, cost], feed_dict={x: X[start:end], noise: _noise})\n",
    "            err_all.append(err)\n",
    "        print('EPOCH:%d, ERROR:%lf' % (epoch+1, np.mean(err_all)))\n",
    "\n",
    "    weight_2 = sess.run(tf.transpose(model.W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 重みの可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- corruption levelの違いによる重みの違いを確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Corruption level=0の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "for i in range(100):\n",
    "    ax = fig.add_subplot(10, 10, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(weight_1[i].reshape((28, 28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Corruption level=0.3の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "for i in range(100):\n",
    "    ax = fig.add_subplot(10, 10, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(weight_2[i].reshape((28, 28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題2. Stacked Denoising Autoencoder (SdA) の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 各クラスの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Autoencoder:\n",
    "    def __init__(self, vis_dim, hid_dim, W, function=lambda x: x):\n",
    "        self.W = W\n",
    "        self.a = tf.Variable(np.zeros(vis_dim).astype('float32'), name='a')\n",
    "        self.b = tf.Variable(np.zeros(hid_dim).astype('float32'), name='b')\n",
    "        self.function = function\n",
    "        self.params = [self.W, self.a, self.b]\n",
    "\n",
    "    def encode(self, x):\n",
    "        u = tf.matmul(x, self.W) + self.b\n",
    "        return self.function(u)\n",
    "    \n",
    "    def decode(self, x):\n",
    "        u = tf.matmul(x, tf.transpose(self.W)) + self.a\n",
    "        return self.function(u)\n",
    "\n",
    "    def f_prop(self, x):\n",
    "        y = self.encode(x)\n",
    "        return self.decode(y)\n",
    "\n",
    "    def reconst_error(self, x, noise):\n",
    "        tilde_x = x * noise\n",
    "        reconst_x = self.f_prop(tilde_x)\n",
    "        error = -tf.reduce_mean(tf.reduce_sum(x * tf.log(reconst_x) + (1. - x) * tf.log(1. - reconst_x), axis=1))\n",
    "        return error, reconst_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 全結合層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    def __init__(self, in_dim, out_dim, function):\n",
    "        self.W = tf.Variable(rng.uniform(low=-0.08, high=0.08, size=(in_dim, out_dim)).astype('float32'), name='W')\n",
    "        self.b = tf.Variable(np.zeros([out_dim]).astype('float32'))\n",
    "        self.function = function\n",
    "        self.params = [self.W, self.b]\n",
    "        \n",
    "        self.ae = Autoencoder(in_dim, out_dim, self.W, self.function)\n",
    "\n",
    "    def f_prop(self, x):\n",
    "        u = tf.matmul(x, self.W) + self.b\n",
    "        self.z = self.function(u)\n",
    "        return self.z\n",
    "\n",
    "    def pretrain(self, x, noise):\n",
    "        cost, reconst_x = self.ae.reconst_error(x, noise)\n",
    "        return cost, reconst_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ネットワークの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "layers = [\n",
    "    Dense(784, 500, tf.nn.sigmoid),\n",
    "    Dense(500, 500, tf.nn.sigmoid),\n",
    "    Dense(500, 10, tf.nn.softmax)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 事前学習 (Pre-training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = np.copy(train_X)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "for l, layer in enumerate(layers[:-1]):\n",
    "    corruption_level = np.float(0.3)\n",
    "    batch_size = 100\n",
    "    n_batches = X.shape[0] // batch_size\n",
    "    n_epochs = 10\n",
    "\n",
    "    x = tf.placeholder(tf.float32)\n",
    "    noise = tf.placeholder(tf.float32)\n",
    "    \n",
    "    cost, reconst_x = layer.pretrain(x, noise)\n",
    "    params = layer.params\n",
    "    train = sgd(cost, params)\n",
    "    encode = layer.f_prop(x)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        X = shuffle(X, random_state=random_state)\n",
    "        err_all = []\n",
    "        for i in range(n_batches):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "\n",
    "            _noise = rng.binomial(size=X[start:end].shape, n=1, p=1-corruption_level)\n",
    "            _, err = sess.run([train, cost], feed_dict={x: X[start:end], noise: _noise})\n",
    "            err_all.append(err)\n",
    "        print('Pretraining:: layer: %d, Epoch: %d, Error: %lf' % (l+1, epoch+1, np.mean(err)))\n",
    "    X = sess.run(encode, feed_dict={x: X})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 計算グラフ構築 & パラメータの更新設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "t = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "def f_props(layers, x):\n",
    "    params = []\n",
    "    for layer in layers:\n",
    "        x = layer.f_prop(x)\n",
    "        params += layer.params\n",
    "    return x, params\n",
    "\n",
    "y, params = f_props(layers, x)\n",
    "\n",
    "cost = -tf.reduce_mean(tf.reduce_sum(t * tf.log(y), 1))\n",
    "updates = sgd(cost, params)\n",
    "\n",
    "train = tf.group(*updates)\n",
    "valid = tf.argmax(y, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 学習 (Fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = train_X.shape[0] // batch_size\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_X, train_y = shuffle(train_X, train_y, random_state=random_state)\n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        sess.run(train, feed_dict={x: train_X[start:end], t: train_y[start:end]})\n",
    "    pred_y, valid_cost = sess.run([valid, cost], feed_dict={x: valid_X, t: valid_y})\n",
    "    print('EPOCH: %i, Validation cost: %.3f Validation F1: %.3f' % (epoch + 1, valid_cost, f1_score(np.argmax(valid_y, 1).astype('int32'), pred_y, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
